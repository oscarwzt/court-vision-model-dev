{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of miss: 49.59%\n"
     ]
    }
   ],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, num_layers):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.resnet = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "        \n",
    "        # RNN (LSTM) layer\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Classification layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, time, channels, height, width]\n",
    "        batch_size, timesteps, C, H, W = x.size()\n",
    "        \n",
    "        # Flatten dimensions for ResNet\n",
    "        x = x.view(batch_size * timesteps, C, H, W)\n",
    "        \n",
    "        # Feature extraction through ResNet\n",
    "        with torch.no_grad():\n",
    "            features = self.resnet(x)\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        features = features.view(batch_size, timesteps, -1)\n",
    "        \n",
    "        # Sequence processing through LSTM\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        \n",
    "        # Classification\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "def preprocess_frame(frame, size=(224, 224)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform(frame)\n",
    "\n",
    "# Function to load and preprocess video\n",
    "def load_video(video_path, max_frames=16):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or len(frames) == max_frames:\n",
    "                break\n",
    "            frame = preprocess_frame(frame)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    \n",
    "    # Stack frames and add batch dimension\n",
    "    frames_tensor = torch.stack(frames)\n",
    "    frames_tensor = frames_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    return frames_tensor\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 1 # Define the number of classes\n",
    "hidden_size = 256 # LSTM hidden size\n",
    "num_layers = 2 # Number of LSTM layers\n",
    "\n",
    "# Model instance\n",
    "model = RNN_Model(num_classes, hidden_size, num_layers)\n",
    "model.to(device)\n",
    "\n",
    "video_path = \"video_test_dataset/0/miss_4.mp4\"\n",
    "video_tensor = load_video(video_path).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(video_tensor)\n",
    "    prob = torch.sigmoid(outputs).item()\n",
    "    \n",
    "print(\"Probability of miss: {:.2f}%\".format(prob * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
