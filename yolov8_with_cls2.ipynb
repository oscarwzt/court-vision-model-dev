{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import random\n",
    "from IPython.display import HTML\n",
    "import torchvision.models as torch_models\n",
    "from base64 import b64encode\n",
    "import os\n",
    "from IPython.display import Video\n",
    "from utils import *\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else device\n",
    "print(device)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "yolo_model_path = \"weights/detect_large.pt\"\n",
    "model = YOLO(yolo_model_path)\n",
    "classNames = ['basketball', 'hoop', 'person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_by_batch(model, \n",
    "                       cls_model,\n",
    "                       video_path, \n",
    "                       cls_conf_threshold = 0.6,\n",
    "                       detect_conf_threshold = 0.4,\n",
    "                       save_result_vid = False, \n",
    "                       output_dir = None, \n",
    "                       saved_video_name = None,\n",
    "                       batch_size=128,\n",
    "                       display_result = False,\n",
    "                       show_progress = True,\n",
    "                       skip_to_sec = 0,\n",
    "                       show_score_prob = False,\n",
    "                       ):\n",
    "    cap, fps, frame_width, frame_height = get_video_info(video_path)\n",
    "    if skip_to_sec > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, skip_to_sec * 1000)\n",
    "        \n",
    "    num_skiped_frames = int(skip_to_sec * fps)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - num_skiped_frames\n",
    "    \n",
    "    \n",
    "    if save_result_vid:\n",
    "        video_name = video_path.split(\"/\")[-1]\n",
    "        video_name = video_name.split(\".\")[0] + \".mp4\"\n",
    "        output_path = \"inferenced_\" + video_name if output_dir is None else os.path.join(output_dir, \"inferenced_\" + video_name)\n",
    "        if saved_video_name is not None:\n",
    "            compressed_output_path = saved_video_name if output_dir is None else os.path.join(output_dir, saved_video_name)\n",
    "        else:\n",
    "            compressed_output_path = \"compressed_inferenced_\" + video_name if output_dir is None else os.path.join(output_dir, \"compressed_inferenced_\" + video_name)\n",
    "        codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, codec, fps, (frame_width,frame_height))\n",
    "    \n",
    "    num_batches = math.ceil(total_frames / batch_size)\n",
    "\n",
    "    results = []\n",
    "    score_timestamps = []\n",
    "    \n",
    "    count = 0\n",
    "    score = 0\n",
    "    display_prob = [0.0]\n",
    "    \n",
    "    if show_progress:\n",
    "        batch_range = tqdm(range(num_batches))\n",
    "    else:\n",
    "        batch_range = range(num_batches)\n",
    "\n",
    "    for i in batch_range:\n",
    "        frames = []\n",
    "        for i in range(batch_size):\n",
    "            ret, img = cap.read()\n",
    "            if ret:\n",
    "                frames.append(img)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if frames:\n",
    "            results = model(frames, \n",
    "                            stream=False, \n",
    "                            verbose = False, \n",
    "                            conf=detect_conf_threshold)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for c, r in enumerate(results):\n",
    "            img = r.orig_img\n",
    "            boxes = r.boxes\n",
    "            cropped_images = []\n",
    "            count += 1\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # convert to int values\n",
    "                confidence = box.conf.item()\n",
    "                predicted_class = model.names[int(box.cls)] \n",
    "                if predicted_class == \"hoop\":\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f'{predicted_class}: {confidence:.3f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                    \n",
    "                    if x1 > x2 or y1 > y2:\n",
    "                        continue\n",
    "                    else:\n",
    "                        cropped_img = img[y1:y2, x1:x2]\n",
    "                        cropped_images.append(cropped_img)\n",
    "                        \n",
    "                if predicted_class == \"basketball\":\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(img, f'{predicted_class}: {confidence:.3f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    \n",
    "            \n",
    "            if len(cropped_images) == 0:\n",
    "                continue\n",
    "            pred, prob = predict_hoop_box_batch(cropped_images, cls_model,  preprocess, device, threshold=cls_conf_threshold)\n",
    "            if pred.sum() > 0 and count > 60:\n",
    "                score += 1\n",
    "                count = 0\n",
    "                current_frame = i * batch_size + c\n",
    "                time_stamp = current_frame / fps\n",
    "                score_timestamps.append((time_stamp, prob))\n",
    "                display_prob = prob\n",
    "        \n",
    "            cv2.putText(img, f'Score: {score}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "            if show_score_prob:\n",
    "                cv2.putText(img, f'Prob: {max(display_prob):.3f}', (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "            if save_result_vid:\n",
    "                out.write(img)\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "    if save_result_vid:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    \n",
    "    if save_result_vid:\n",
    "        subprocess.run(['ffmpeg', '-y', '-hide_banner',  '-loglevel', 'error', '-i', output_path, '-vcodec', 'libx264', compressed_output_path], check=False)\n",
    "        os.remove(output_path)\n",
    "        if display_result:\n",
    "            display(Video(compressed_output_path, embed=True))\n",
    "        return score_timestamps, compressed_output_path\n",
    "    else:\n",
    "        return score_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_by_frame(model, \n",
    "                       cls_model,\n",
    "                       video_path, \n",
    "                       cls_conf_threshold = 0.6,\n",
    "                       detect_conf_threshold = 0.4,\n",
    "                       save_result_vid = False, \n",
    "                       output_dir = None, \n",
    "                       saved_video_name = None,\n",
    "                       display_result = False,\n",
    "                       show_progress = True,\n",
    "                       skip_to_sec = 0,\n",
    "                       show_score_prob = False,\n",
    "                       \n",
    "                       ):\n",
    "    cap, fps, frame_width, frame_height = get_video_info(video_path)\n",
    "    if skip_to_sec > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, skip_to_sec * 1000)\n",
    "        \n",
    "    num_skiped_frames = int(skip_to_sec * fps)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - num_skiped_frames\n",
    "    \n",
    "    \n",
    "    if save_result_vid:\n",
    "        video_name = video_path.split(\"/\")[-1]\n",
    "        video_name = video_name.split(\".\")[0] + \".mp4\"\n",
    "        output_path = \"inferenced_\" + video_name if output_dir is None else os.path.join(output_dir, \"inferenced_\" + video_name)\n",
    "        if saved_video_name is not None:\n",
    "            compressed_output_path = saved_video_name if output_dir is None else os.path.join(output_dir, saved_video_name)\n",
    "        else:\n",
    "            compressed_output_path = \"compressed_inferenced_\" + video_name if output_dir is None else os.path.join(output_dir, \"compressed_inferenced_\" + video_name)\n",
    "        codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, codec, fps, (frame_width,frame_height))\n",
    "    pbar = tqdm(total=total_frames, desc=\"Processing Frames\", unit=\"frame\") if show_progress else None\n",
    "\n",
    "    score_timestamps = []\n",
    "    count=0\n",
    "    score = 0\n",
    "    display_prob = [0.0]\n",
    "    \n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        frame_start_time = time.time()\n",
    "        current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        count += 1\n",
    "        if ret:\n",
    "            results = model(img, stream = False, device = device, conf = detect_conf_threshold, verbose = False)\n",
    "            \n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                    confidence = box.conf[0]\n",
    "                    predicted_class = model.names[int(box.cls)]\n",
    "                    \n",
    "                    # If \"basketball-hoops\" is detected, make a prediction with cls_model\n",
    "                    if predicted_class == \"hoop\":\n",
    "                        # Crop the image and convert to PIL Image\n",
    "                        # try:\n",
    "                        if x1 > x2 or y1 > y2:\n",
    "                            continue\n",
    "                        else:\n",
    "                            _, prediction, prob = predict_hoop_box(img, cls_model, x1, y1, x2, y2, preprocess, device, cls_conf_threshold)\n",
    "                            if prediction == 1 and count > 60:\n",
    "                                score += 1\n",
    "                                count = 0\n",
    "                                display_prob = prob\n",
    "                                score_timestamps.append((current_time, prob))\n",
    "\n",
    "                        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        cv2.putText(img, f'{predicted_class}: {confidence:.3f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                    \n",
    "                    if predicted_class == \"basketball\":\n",
    "                        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.putText(img, f'{predicted_class}: {confidence:.3f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(img, f'Score: {score}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "            if show_score_prob:\n",
    "                cv2.putText(img, f'Prob: {display_prob[0]:.3f}', (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "\n",
    "            if show_progress:\n",
    "                frame_end_time = time.time()  # End time for frame processing\n",
    "                time_per_frame = frame_end_time - frame_start_time\n",
    "                pbar.set_postfix(time_per_frame=f\"{time_per_frame:.3f} sec\")\n",
    "                pbar.update(1)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        if save_result_vid:\n",
    "            out.write(img)\n",
    "            \n",
    "    if save_result_vid:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    \n",
    "    if save_result_vid:\n",
    "        subprocess.run(['ffmpeg', '-y', '-hide_banner',  '-loglevel', 'error', '-i', output_path, '-vcodec', 'libx264', compressed_output_path], check=False)\n",
    "        os.remove(output_path)\n",
    "        if display_result:\n",
    "            display(Video(compressed_output_path, embed=True))\n",
    "        return score_timestamps, compressed_output_path\n",
    "    else:\n",
    "        return score_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, cls_model, all_made, all_miss, conf = 0.5):\n",
    "    true_labels = np.array([1] * len(os.listdir(all_made)) + [0] * len(os.listdir(all_miss)))\n",
    "    predictions = np.empty(len(true_labels))\n",
    "    i = 0\n",
    "    for cls in [all_made, all_miss]:\n",
    "        for vid in tqdm(os.listdir(cls)):\n",
    "            vid = cls + f\"/{vid}\"\n",
    "            result = inference_by_batch(model,\n",
    "                                        cls_model,\n",
    "                                        video_path = vid,\n",
    "                                        save_result_vid = False,\n",
    "                                        display_result = False,\n",
    "                                        batch_size = 128,\n",
    "                                        show_progress=False,\n",
    "                                        cls_conf_threshold=conf)\n",
    "            \n",
    "            predictions[i] = len(result) > 0\n",
    "            i += 1\n",
    "    conf_mat = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    return true_labels, predictions, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "test_set_dir = \"video_test_dataset\"\n",
    "all_made = test_set_dir + \"/1/\"\n",
    "all_miss = test_set_dir + \"/0/\"\n",
    "print(len(os.listdir(all_made)) + len(os.listdir(all_miss)))\n",
    "made_vids = os.listdir(all_made)\n",
    "\n",
    "resnet_50 = load_resnet50(\"cls_chkpoint_resnet50/checkpoint_2023-12-18-21-45_lr_0.0001_batch_64/best_model.pth\", device=device)\n",
    "resnet_50.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(447.41363333333334, [0.010158891789615154, 0.4117841422557831])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_by_batch(model, \n",
    "                   resnet_50,\n",
    "                   video_path = all_made + made_vids[0],\n",
    "                   save_result_vid = False,\n",
    "                   display_result = False,\n",
    "                   batch_size = 128,\n",
    "                   show_progress=False,\n",
    "                   cls_conf_threshold=0.3,\n",
    "                   detect_conf_threshold=0.4,\n",
    "                   show_score_prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [07:49<00:00,  5.52s/it]\n",
      "100%|██████████| 75/75 [07:13<00:00,  5.79s/it]\n"
     ]
    }
   ],
   "source": [
    "results = test_model(model, resnet_50, all_made, all_miss, conf = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = results[0] == results[1]\n",
    "accuracy = accuracy.sum() / len(accuracy)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
