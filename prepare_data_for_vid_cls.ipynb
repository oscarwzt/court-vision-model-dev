{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import random\n",
    "import os\n",
    "from IPython.display import Video\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from collections import deque\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video_test_dataset/1/made_1.mp4\" controls  width=\"640\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"video_test_dataset/1/made_1.mp4\"\n",
    "Video(video_path, width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"weights/detect_large.pt\")\n",
    "\n",
    "video_path = \"video_test_dataset/1/made_5.mp4\"\n",
    "output_dir = \"cropped_video_dataset\"\n",
    "detect_conf_threshold = 0.7\n",
    "\n",
    "#def create_zoomed_in_hoop_video(video_path, detect_conf_threshold=0.7, output_dir = \"cropped_video_dataset\", display_result = False):                 \n",
    "cap, fps, frame_width, frame_height = get_video_info(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "\n",
    "\n",
    "video_name = video_path.split(\"/\")[-1]\n",
    "video_name = video_name.split(\".\")[0] \n",
    "\n",
    "center_buffer = deque(maxlen=10)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "already_intialized_video = False \n",
    "last_known_center = None\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(total_frames)):\n",
    "    ret, img = cap.read()\n",
    "    hoop_detected = False\n",
    "    if ret:\n",
    "        results = model(img, stream = False, device = device, conf = detect_conf_threshold, verbose = False)\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                confidence = box.conf[0]\n",
    "                predicted_class = model.names[int(box.cls)]\n",
    "                \n",
    "                # If \"basketball-hoops\" is detected, make a prediction with cls_model\n",
    "                if predicted_class == \"hoop\" and confidence > detect_conf_threshold:\n",
    "                    hoop_detected = True\n",
    "                    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                    last_known_center = (center_x, center_y)\n",
    "                    \n",
    "                    box_width = x2 - x1\n",
    "                    box_height = y2 - y1\n",
    "                    x1 = int(x1 - box_width / 2)\n",
    "                    y1 = int(y1 - box_height / 2)\n",
    "                    x2 = int(x2 + box_width / 2)\n",
    "                    y2 = int(y2 + box_height / 2)\n",
    "                    \n",
    "                    \n",
    "                    if not already_intialized_video:\n",
    "                        already_intialized_video = True\n",
    "                        crop_width = x2 - x1\n",
    "                        crop_height = y2 - y1\n",
    "                        new_vid_fps = fps\n",
    "                        new_vid_codec = cv2.VideoWriter_fourcc(*'vp09')\n",
    "                        new_vid_name = video_name + \"_cropped.mp4\"\n",
    "                        new_vid_path = os.path.join(output_dir, new_vid_name) if output_dir is not None else new_vid_name\n",
    "                        new_vid = cv2.VideoWriter(new_vid_path, new_vid_codec, new_vid_fps, (crop_width, crop_height))\n",
    "\n",
    "                    else:\n",
    "                        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                        center_buffer.append((center_x, center_y))  # Add current center to the buffer\n",
    "\n",
    "                        # Calculate smoothed center\n",
    "                        avg_center_x, avg_center_y = map(int, np.mean(center_buffer, axis=0))\n",
    "\n",
    "                        # Rest of your cropping logic, but use avg_center_x and avg_center_y for cropping\n",
    "                        x1_crop = max(avg_center_x - crop_width // 2, 0)\n",
    "                        y1_crop = max(avg_center_y - crop_height // 2, 0)\n",
    "                        x2_crop = min(x1_crop + crop_width, img.shape[1])\n",
    "                        y2_crop = min(y1_crop + crop_height, img.shape[0])\n",
    "\n",
    "                        # Adjust the crop area if it exceeds the image size\n",
    "                        x1_crop = max(x2_crop - crop_width, 0)\n",
    "                        y1_crop = max(y2_crop - crop_height, 0)\n",
    "                        \n",
    "                        img_crop = img[y1_crop:y2_crop, x1_crop:x2_crop]\n",
    "                        new_vid.write(img_crop)\n",
    "                        \n",
    "    if not hoop_detected and last_known_center is not None:\n",
    "        # Use the last known center for cropping if hoop is not detected\n",
    "        center_x, center_y = last_known_center\n",
    "        center_buffer.append(last_known_center)  # Update center buffer with the last known center\n",
    "\n",
    "        if already_intialized_video and not img is None:\n",
    "            # Calculate smoothed center\n",
    "            avg_center_x, avg_center_y = map(int, np.mean(center_buffer, axis=0))            \n",
    "            x1_crop = max(avg_center_x - crop_width // 2, 0)\n",
    "            y1_crop = max(avg_center_y - crop_height // 2, 0)\n",
    "            x2_crop = min(x1_crop + crop_width, img.shape[1])\n",
    "            y2_crop = min(y1_crop + crop_height, img.shape[0])\n",
    "\n",
    "            # Adjust the crop area if it exceeds the image size\n",
    "            x1_crop = max(x2_crop - crop_width, 0)\n",
    "            y1_crop = max(y2_crop - crop_height, 0)\n",
    "            \n",
    "            img_crop = img[y1_crop:y2_crop, x1_crop:x2_crop]\n",
    "            new_vid.write(img_crop)    \n",
    "                \n",
    "\n",
    "\n",
    "    elif not ret:\n",
    "        break\n",
    "    \n",
    "if already_intialized_video:\n",
    "    new_vid.release()\n",
    "cap.release()\n",
    "\n",
    "    \n",
    "    #return new_vid_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:05<00:00, 29.53it/s]\n",
      "100%|██████████| 85/85 [00:02<00:00, 39.75it/s]\n",
      "100%|██████████| 158/158 [00:01<00:00, 87.58it/s]\n",
      "100%|██████████| 108/108 [00:03<00:00, 29.54it/s]\n",
      "100%|██████████| 135/135 [00:03<00:00, 36.10it/s]\n",
      "100%|██████████| 104/104 [00:02<00:00, 44.65it/s]\n",
      "100%|██████████| 155/155 [00:04<00:00, 32.10it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 43.49it/s]\n",
      "100%|██████████| 91/91 [00:07<00:00, 12.24it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.68it/s]\n",
      "100%|██████████| 108/108 [00:08<00:00, 12.10it/s]\n",
      "100%|██████████| 190/190 [00:01<00:00, 116.92it/s]\n",
      "100%|██████████| 90/90 [00:07<00:00, 11.69it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 29.53it/s]\n",
      "100%|██████████| 79/79 [00:06<00:00, 12.43it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'last_known_center' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(root_dir):\n\u001b[1;32m     10\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_dir, video_name)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mcreate_zoomed_in_hoop_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetect_conf_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_result\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 79\u001b[0m, in \u001b[0;36mcreate_zoomed_in_hoop_video\u001b[0;34m(video_path, detect_conf_threshold, output_dir, display_result)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     img_crop \u001b[38;5;241m=\u001b[39m img[y1_crop:y2_crop, x1_crop:x2_crop]\n\u001b[1;32m     77\u001b[0m                     new_vid\u001b[38;5;241m.\u001b[39mwrite(img_crop)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hoop_detected \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mlast_known_center\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# Use the last known center for cropping if hoop is not detected\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     center_x, center_y \u001b[38;5;241m=\u001b[39m last_known_center\n\u001b[1;32m     82\u001b[0m     center_buffer\u001b[38;5;241m.\u001b[39mappend(last_known_center)  \u001b[38;5;66;03m# Update center buffer with the last known center\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'last_known_center' referenced before assignment"
     ]
    }
   ],
   "source": [
    "root_data_dir = \"video_test_dataset\"\n",
    "output_root_dir = \"cropped_video_dataset\"\n",
    "\n",
    "classes = [\"0\", \"1\"]\n",
    "\n",
    "for cls in classes:\n",
    "    root_dir = os.path.join(root_data_dir, cls)\n",
    "    output_dir = os.path.join(output_root_dir, cls)\n",
    "    for video_name in os.listdir(root_dir):\n",
    "        video_path = os.path.join(root_dir, video_name)\n",
    "        create_zoomed_in_hoop_video(video_path, detect_conf_threshold, output_dir, display_result = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"video_test_dataset/1/made_5.mp4\"\n",
    "output_dir = \"cropped_video_dataset\"\n",
    "\n",
    "cap, fps, frame_width, frame_height = get_video_info(video_path)\n",
    "out = cv2.VideoWriter('output.mp4',cv2.VideoWriter_fourcc(*\"vp09\"), fps, (frame_width,frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        result = model.track(frame, persist = True, device = \"cuda\")\n",
    "        \n",
    "        annotated_frame = result[0].plot()\n",
    "        out.write(annotated_frame)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  width=\"640\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"output.mp4\", width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
